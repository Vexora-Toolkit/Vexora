---
title: Installation
description: Get started with vexora in under a minute
icon: download
---

## Requirements

- Python 3.10 or higher
- An API key from an LLM provider (OpenAI by default)

## Install `vexora`

The easiest way to install vexora is a package manager like `pip` or [`uv`](https://docs.astral.sh/uv/):

<CodeGroup>

```bash pip
pip install vexora
```

```bash uv
uv add vexora
# or
uv pip install vexora
```

</CodeGroup>

## Configure your LLM provider

By default, vexora uses OpenAI's models. Set your API key as an environment variable:

```bash
export OPENAI_API_KEY="your-api-key"
```

To use another provider, see the docs on [configuring LLMs](/guides/configure-llms).

## Development Installation

For development, install vexora with development dependencies:

<CodeGroup>

```bash pip
git clone https://github.com/prefecthq/vexora.git
cd vexora
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
```

```bash uv
git clone https://github.com/prefecthq/vexora.git
cd vexora
uv venv && source .venv/bin/activate
uv sync --dev
```

</CodeGroup>

## What's Next?

- Follow the [Quickstart](/quickstart) guide to build your first AI application
- Learn about [Tasks](/concepts/tasks), the building blocks of AI workflows
- Explore [Agents](/concepts/agents) to create specialized AI workers
- Read about [Threads](/concepts/threads) for managing conversation context 